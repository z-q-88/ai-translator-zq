import streamlit as st
from groq import Groq
from streamlit_mic_recorder import mic_recorder
import streamlit.components.v1 as components
import os

# --- 1. åˆå§‹åŒ–è®¾ç½® ---
st.set_page_config(page_title="ğŸ§â€â™‚ï¸ AI æ™ºèƒ½ä¼ è¯‘ (ä¸¥æ ¼ä¼ å£°ç­’ç‰ˆ)", layout="centered")

# âš ï¸âš ï¸âš ï¸ å®‰å…¨ä¿®æ”¹ï¼šä¸è¦ç›´æ¥åœ¨ä»£ç é‡Œå†™ Key âš ï¸âš ï¸âš ï¸
# åŸæ¥çš„ä»£ç ï¼šAPI_KEY = "gsk_xxxx..." (åˆ æ‰ï¼)

# æ–°çš„ä»£ç ï¼šå‘Šè¯‰ç¨‹åºå»â€œäº‘ç«¯ä¿é™©ç®± (Secrets)â€é‡Œæ‰¾é’¥åŒ™
try:
    API_KEY = st.secrets["GROQ_API_KEY"]
    client = Groq(api_key=API_KEY)
except Exception as e:
    st.error("ğŸš¨ è¿˜æ²¡é…ç½®å¯†é’¥ï¼éƒ¨ç½²åè¯·åœ¨ Streamlit Secrets é‡Œå¡«å…¥ GROQ_API_KEYã€‚")
    st.stop()

# åˆå§‹åŒ– Session State
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_processed_audio" not in st.session_state:
    st.session_state.last_processed_audio = None

# --- 2. æ ¸å¿ƒå¤§è„‘ (Translation - ä¸¥æ ¼æ¨¡å¼) ğŸ§  ---
def ai_translator(text_input, target_lang="en"):
    if target_lang == "en":
        # ğŸŸ¢ æ ¸å¿ƒä¿®æ”¹ï¼šä¸­ -> è‹± (ä¸¥æ ¼ä¼ å£°ç­’æ¨¡å¼)
        system_prompt = """
        You are a neutral real-time translation tool, NOT an assistant or a salesperson.
        
        YOUR MISSION:
        Translate the user's Chinese text directly and accurately into English.
        
        CRITICAL RULES (DO NOT IGNORE):
        1. NO Interpretation: Do not explain the context (e.g., do not mention shipping, FOB, or software speed).
        2. NO Answering: Do not answer the user's question. If the user asks "Can you be faster?", translate that question into English, do not answer "Yes I can".
        3. NO Additions: Do not add polite phrases or sales terminology (like "Dear customer") unless they are in the original text.
        4. Output ONLY the translated English text.
        """
    else:
        # ğŸ”µ è‹± -> ä¸­ (ä¿æŒç®€ä½“ä¸­æ–‡ + å‡†ç¡®ç¿»è¯‘)
        system_prompt = """
        You are a translator. Translate the English text into clear, natural Simplified Chinese (ç®€ä½“ä¸­æ–‡).
        Output ONLY the translation. Do NOT use Traditional Chinese.
        Do NOT answer the question, just translate it.
        """
    
    try:
        completion = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text_input}
            ],
            temperature=0.6,
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"Error: {str(e)}"

# --- 3. æ ¸å¿ƒè€³æœµ (Auto-Detect Language) ---
def transcribe_auto_detect(file_path):
    try:
        with open(file_path, "rb") as file:
            result = client.audio.transcriptions.create(
                file=(file_path, file.read()),
                model="whisper-large-v3",
                response_format="verbose_json" 
            )
        return result.text, result.language
    except Exception as e:
        st.error(f"å¬è§‰æ•…éšœ: {str(e)}")
        return "", ""

# --- 4. æé€Ÿå‘éŸ³ (JS) ---
def speak_instant(text, lang="en"):
    safe_text = text.replace('"', '\\"').replace("'", "\\'").replace("\n", " ")
    lang_code = 'en-US' if lang == 'en' else 'zh-CN'
    js_code = f"""
    <script>
        window.speechSynthesis.cancel();
        var msg = new SpeechSynthesisUtterance("{safe_text}");
        msg.lang = "{lang_code}";
        window.speechSynthesis.speak(msg);
    </script>
    """
    components.html(js_code, height=0)

# --- 5. ç•Œé¢å¸ƒå±€ ---
st.title("ğŸ§â€â™‚ï¸ AI æ™ºèƒ½ä¼ è¯‘ (ä¸¥æ ¼ç‰ˆ)")

status_area = st.empty()
status_area.info("ğŸ’¡ æç¤ºï¼šç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹ï¼Œè¯´å®Œè¯åã€å¿…é¡»å†æ¬¡ç‚¹å‡»ã€‘æŒ‰é’®æ¥å‘é€ã€‚")

# A. èŠå¤©è®°å½•
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# B. åº•éƒ¨æ“ä½œåŒº
st.divider()

audio_data = mic_recorder(
    start_prompt="ğŸ”´ ç‚¹å‡»å¼€å§‹å½•éŸ³", 
    stop_prompt="â¹ï¸ å½•éŸ³ä¸­... (è¯´å®Œç‚¹æ­¤å‘é€)", 
    key='auto_rec'
)

# --- C. æ™ºèƒ½é€»è¾‘å¤„ç† ---
if audio_data:
    current_bytes = audio_data['bytes']
    if current_bytes != st.session_state.last_processed_audio:
        
        status_area.warning("â³ æ­£åœ¨å¤„ç†éŸ³é¢‘ï¼Œè¯·ç¨å€™...")
        
        with open("temp_audio.wav", "wb") as f: f.write(current_bytes)
        
        text_origin, detected_lang = transcribe_auto_detect("temp_audio.wav")
        
        if text_origin:
            # ğŸŸ¢ æƒ…å†µä¸€ï¼šä¸­æ–‡ -> æˆ‘ -> ç¿»è¯‘å¹¶æ’­æ”¾
            if "chinese" in detected_lang.lower():
                status_area.success("âœ… è¯†åˆ«ä¸ºä¸­æ–‡ï¼šè¯­éŸ³å·²å‘é€ç»™å®¢æˆ·ï¼")
                
                st.session_state.messages.append({"role": "user", "content": f"æˆ‘(CN): {text_origin}"})
                text_translated = ai_translator(text_origin, target_lang="en")
                st.session_state.messages.append({"role": "assistant", "content": f"AI(EN): {text_translated}"})
                speak_instant(text_translated, lang="en")

            # ğŸ”µ æƒ…å†µäºŒï¼šè‹±æ–‡ -> å®¢æˆ· -> ä»…ç¿»è¯‘æ–‡å­—
            elif "english" in detected_lang.lower():
                status_area.info("ğŸ“© è¯†åˆ«ä¸ºè‹±æ–‡ï¼šæ”¶åˆ°å®¢æˆ·æ¶ˆæ¯ï¼ˆé™éŸ³æ¨¡å¼ï¼‰")
                
                st.session_state.messages.append({"role": "user", "content": f"ğŸ‘± å®¢æˆ·(EN): {text_origin}"})
                text_translated = ai_translator(text_origin, target_lang="zh")
                st.session_state.messages.append({"role": "assistant", "content": f"ğŸ‘€ ç¿»è¯‘(CN): {text_translated}"})
                
            else:
                status_area.error(f"âš ï¸ æœªè¯†åˆ«è¯­è¨€ ({detected_lang})ï¼Œè¯·é‡è¯•ã€‚")

            st.session_state.last_processed_audio = current_bytes
            st.rerun()